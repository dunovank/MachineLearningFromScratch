{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after having taken a look at linear regression, it makes sense to also examine logistic regression.\n",
    "First, let's import some packages and generate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_1 = pd.Series(np.random.randn(5))\n",
    "X1_2 = pd.Series(np.random.randn(5)+4)\n",
    "X1 = pd.concat([X1_1, X1_2]).reset_index(drop=True)\n",
    "X2 = pd.Series(np.random.randn(10))\n",
    "Y = pd.Series([0,0,0,0,0,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X1, X2, Y], axis=1)\n",
    "data.columns= [\"X1\", \"X2\", \"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.919050</td>\n",
       "      <td>-0.813152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.678458</td>\n",
       "      <td>-0.028664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.987853</td>\n",
       "      <td>0.524188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.614614</td>\n",
       "      <td>1.752247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250581</td>\n",
       "      <td>0.572468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.419844</td>\n",
       "      <td>-0.205971</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.990395</td>\n",
       "      <td>0.077558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.456785</td>\n",
       "      <td>-0.253241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.112454</td>\n",
       "      <td>-0.262105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.151400</td>\n",
       "      <td>0.181268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2  Y\n",
       "0 -0.919050 -0.813152  0\n",
       "1  0.678458 -0.028664  0\n",
       "2 -0.987853  0.524188  0\n",
       "3 -1.614614  1.752247  0\n",
       "4  0.250581  0.572468  0\n",
       "5  4.419844 -0.205971  1\n",
       "6  3.990395  0.077558  1\n",
       "7  3.456785 -0.253241  1\n",
       "8  4.112454 -0.262105  1\n",
       "9  5.151400  0.181268  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can find a linear decision boundary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'First Look at Data')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 402.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.lmplot(x=\"X1\", y=\"X2\", data=data, hue=\"Y\", fit_reg=False)\n",
    "plt.title('First Look at Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evident from our plot, we can fit a linear decision boundary. Therefore, a logistic regression might be a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will have two coefficients, $X_1$ and $X_2$. Unlike in our linear regression, we can't just use $Y = b_0 + b_1*X_1+ b_2*X_2$. Instead, we are going to have to transform our output into probabilities using the logistic function (sigmoid function): $P(Y=1|X=x) = 1/1+exp(-b_0 + b_1*X_1+ b_2*X_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find our coefficients, we can again rely on stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's assign 0 to our betas to initialize them\n",
    "beta0 = 0.\n",
    "beta1 = 0.\n",
    "beta2 = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify our computations, let's define a function for our sigmoid computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(beta0, beta1, beta2, X1, X2):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    This function takes the beta parameters beta0, beta1, and beta2,\n",
    "    as well as X1 and X2 as inputs\n",
    "    \n",
    "    Output:\n",
    "    After having transformed the inputs into a real value between 0\n",
    "    and 1, the function will return said value that can be interpreted\n",
    "    as a probability\n",
    "    \"\"\"\n",
    "    prepared = beta0 + beta1*X1 + beta2*X2\n",
    "    prediction = 1/(1 + np.exp(-prepared))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test that using our first training instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2, Y = list(data.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first prediction is 0.5\n"
     ]
    }
   ],
   "source": [
    "first_prediction = sigmoid(beta0, beta1, beta2, X1, X2)\n",
    "print(\"Our first prediction is {}\".format(first_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate New Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coefficients(beta0, beta1, beta2, X1, X2, Y, prediction):\n",
    "    \"\"\"\n",
    "    This function takes the training instance as well as the betas\n",
    "    and the previously calculated prediction to update the coefficients\n",
    "    \"\"\"\n",
    "    alpha = 0.3\n",
    "    bias_of_intercept = 1.0\n",
    "    beta0 = beta0 + alpha*(Y-prediction)*prediction*(1-prediction)*bias_of_intercept\n",
    "    beta1 = beta1 + alpha*(Y-prediction)*prediction*(1-prediction)*X1\n",
    "    beta2 = beta2 + alpha*(Y-prediction)*prediction*(1-prediction)*X2\n",
    "    \n",
    "    return beta0, beta1, beta2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our updated parameters are:\n",
      "beta0: -0.0375\n",
      "beta1: -0.020980870585683948\n",
      "beta2: -0.03909196554528134\n"
     ]
    }
   ],
   "source": [
    "beta0, beta1, beta2 = update_coefficients(beta0, beta1, beta2, X1, X2, Y, first_prediction)\n",
    "print(\"Our updated parameters are:\\nbeta0: {}\\nbeta1: {}\\nbeta2: {}\".format(beta0, beta1, beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we certainly aren't going to manually repeat that for all training instances/epochs. Therefore, let's write some code that'll do so for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def putting_it_together(epochs=1, learning_rate=0.3, cutoff=0.5):\n",
    "    \"\"\"\n",
    "    This function performs a stochastic gradient descent\n",
    "    and returns the final coefficients\n",
    "    \"\"\"\n",
    "    beta0 = 0.\n",
    "    beta1 = 0.\n",
    "    beta2 = 0.\n",
    "    bias_of_intercept = 1.0\n",
    "    alpha = learning_rate\n",
    "    \n",
    "\n",
    "    for i in range(1,epochs+1):\n",
    "        \n",
    "        correct_predictions = 0\n",
    "        print('\\nThis is epoch number {}:\\n'.format(i), '-'*60)\n",
    "        \n",
    "        for n in range(len(data.X1)):\n",
    "\n",
    "            X1 = data.iloc[n,0]\n",
    "            X2 = data.iloc[n,1]\n",
    "            Y = data.iloc[n,2]\n",
    "\n",
    "            prediction = sigmoid(beta0, beta1, beta2, X1, X2)\n",
    "\n",
    "            beta0, beta1, beta2 = update_coefficients(beta0, beta1, beta2, X1, X2, Y, prediction)\n",
    "            \n",
    "            if prediction < cutoff:\n",
    "                class_ = 0\n",
    "            else:\n",
    "                class_ = 1\n",
    "                \n",
    "            if class_ == Y:\n",
    "                correct_predictions+=1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            print('(Instance Number {}) Beta0: {:.3f}, Beta1: {:.3f}, Beta2: {:.3f}, prediction: {}, class: {}, actual class: {}'.format(n+1, beta0, beta1, beta2, prediction, class_, Y))\n",
    "        \n",
    "        accuracy = (correct_predictions/len(data.X1))*100\n",
    "        print('\\nAccuracy of this epoch: {}%\\n'.format(accuracy), '-'*60)\n",
    "    return beta0, beta1, beta2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is epoch number 1:\n",
      " ------------------------------------------------------------\n",
      "(Instance Number 1) Beta0: -0.037, Beta1: -0.021, Beta2: -0.039, prediction: 0.5, class: 0, actual class: 0\n",
      "(Instance Number 2) Beta0: -0.074, Beta1: -0.010, Beta2: -0.035, prediction: 0.49318256187851595, class: 0, actual class: 0\n",
      "(Instance Number 3) Beta0: -0.110, Beta1: 0.030, Beta2: -0.061, prediction: 0.4777504730569901, class: 0, actual class: 0\n",
      "(Instance Number 4) Beta0: -0.144, Beta1: 0.069, Beta2: -0.078, prediction: 0.45645333162008134, class: 0, actual class: 0\n",
      "(Instance Number 5) Beta0: -0.181, Beta1: 0.104, Beta2: -0.008, prediction: 0.48480217726825375, class: 0, actual class: 0\n",
      "(Instance Number 6) Beta0: -0.148, Beta1: 0.239, Beta2: 0.003, prediction: 0.5623015703558849, class: 1, actual class: 1\n",
      "(Instance Number 7) Beta0: -0.130, Beta1: 0.317, Beta2: 0.018, prediction: 0.709114917067449, class: 1, actual class: 1\n",
      "(Instance Number 8) Beta0: -0.121, Beta1: 0.361, Beta2: 0.006, prediction: 0.8095023471228494, class: 1, actual class: 1\n",
      "(Instance Number 9) Beta0: -0.099, Beta1: 0.410, Beta2: 0.063, prediction: 0.661298222653969, class: 1, actual class: 1\n",
      "(Instance Number 10) Beta0: -0.094, Beta1: 0.433, Beta2: 0.070, prediction: 0.8608443171411484, class: 1, actual class: 1\n",
      "\n",
      "Accuracy of this epoch: 100.0%\n",
      " ------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.09365218577751816, 0.4327485087356591, 0.06966238871399635)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "putting_it_together(cutoff = 0.51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! After slighty adjusting the cut-off probability, we manage to achieve 100% accuracy, where $Accuracy = (Correct Predictions/Total Predictions) * 100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
